{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 10\n",
    "\n",
    "Welcome to the assignment for week 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: UNet for Semantic Segmentation\n",
    "\n",
    "In this assignement we are going to program our own UNet model (https://arxiv.org/pdf/1505.04597.pdf). This model outputs a segmentation map. This segmentation map can be a little bit smaller than the true map but should keep the same spatial structure. This map however is composed of several layers, one per class. The goal of the network is to activate a each class layer according to the detected pixels per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\", width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to take this picture as a reference when designing your UNet, but you don't have to stick to the these layer dimensions exactly. You know several techniques to downsample and upsample an image or (latent activation of an image) by now. Use them to your advantage. Don't forget the skip connections, indicated as horizontal grey arrows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10.0 Prepare the PascalVOC dataset\n",
    "\n",
    "* To speed things up, you will find code for preparing the PascalVOC dataset. \n",
    "* Prepare the dataset for your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCSegLoader(torchvision.datasets.VOCSegmentation):\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 year='2012',\n",
    "                 image_set='train',\n",
    "                 download=False,\n",
    "                 transform=None,\n",
    "                 target_transform=None,\n",
    "                 transforms=None):\n",
    "\n",
    "        super(VOCSegLoader, self).__init__(root, year, image_set, download, transform, target_transform, transforms)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is the image segmentation.\n",
    "        \"\"\"\n",
    "        img = Image.open(self.images[index]).convert('RGB')\n",
    "        target = Image.open(self.masks[index])\n",
    "\n",
    "        target = np.array(target)\n",
    "        target[target == 255] = 0\n",
    "        target = Image.fromarray(target)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        target = torch.as_tensor(np.asarray(target, dtype=np.uint8), dtype=torch.long)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_epochs = 3\n",
    "batch_size_train = 100\n",
    "batch_size_val = 100\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "log_interval = 10\n",
    "image_size = (64, 85)\n",
    "\n",
    "\n",
    "transform_data = torchvision.transforms.Compose([torchvision.transforms.Resize(image_size),\n",
    "                                                 torchvision.transforms.ToTensor()])\n",
    "transform_label = torchvision.transforms.Compose([torchvision.transforms.Resize(image_size, interpolation=0)])\n",
    "\n",
    "\n",
    "train_dataset = VOCSegLoader('./data', year='2012', image_set='train', download=True,\n",
    "                             transform=transform_data, target_transform=transform_label)\n",
    "val_dataset = VOCSegLoader('./data', year='2012', image_set='val', download=True,\n",
    "                           transform=transform_data , target_transform=transform_label)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size_train)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataloader, num_samples=5):\n",
    "    # Get a batch of data\n",
    "    dataiter = iter(dataloader)\n",
    "    images, masks = next(dataiter)\n",
    "    \n",
    "    # Create a figure with a grid of subplots\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(10, num_samples * 3))\n",
    "    \n",
    "    for idx in range(num_samples):\n",
    "        # Get image and mask for current sample\n",
    "        img = images[idx]\n",
    "        mask = masks[idx]\n",
    "        \n",
    "        # Convert tensor to PIL Image for display\n",
    "        img_display = to_pil_image(img)\n",
    "        \n",
    "        # Display original image\n",
    "        axes[idx, 0].imshow(img_display)\n",
    "        axes[idx, 0].set_title(f'Sample {idx + 1} - Image')\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        # Display segmentation mask\n",
    "        axes[idx, 1].imshow(mask.numpy(), cmap='tab20')\n",
    "        axes[idx, 1].set_title(f'Sample {idx + 1} - Target Mask')\n",
    "        axes[idx, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples from the training set\n",
    "print(\"Visualizing 5 samples from the training set:\")\n",
    "visualize_samples(train_loader, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10.1 Setting up and training your UNet model\n",
    "\n",
    "* Implement your UNet model. Make use of down- and upsampling techniques. **(RESULT)**\n",
    "* Build a training loop for your model and train it for a few minutes. **(RESULT)**\n",
    "* Report the model performance using a fitting metric for semantic segmentation. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10.2 Reinjection Link Manipulation (BONUS)\n",
    "\n",
    "* Implement a way to manipulate the reinjection links in the UNet model and retrain without them. **(RESULT)**\n",
    "* Report the change in performance with respect to your previous model. **(RESULT)**\n",
    "* Implement an alternative model without reinjection links or down-and upsampling with a roughly similar number of parameters. Retrain and compare the new model's performance to your UNet models for this task. Which one performs best? **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratz, you made it! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
